# -*- coding: utf-8 -*-
"""NBA MVP 2024 Machine Learning

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KXT8RdHGcRwpULA3o91Ioj2KHN4L6UuD
"""

from google.colab import drive
from sklearn import metrics
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix
from sklearn.model_selection import GridSearchCV, StratifiedKFold
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot
import numpy
import pandas
import seaborn
import warnings
warnings.filterwarnings('ignore')

pandas.set_option('display.max_columns', None)

drive.mount('/content/drive')

df = pandas.read_csv('/content/drive/MyDrive/nba_mvp_1980_2024.csv', sep = ',', decimal = '.')
df.tail()

df['Wins'] = df.Overall.apply(lambda x: x.split('-')[0]).astype(int)
df['Losses'] = df.Overall.apply(lambda x: x.split('-')[1]).astype(int)
df['W/L%'] = df.Wins / (df.Wins + df.Losses)
df['GS%'] = df.GS / df.G
df['GP%'] = df.G / (df.Wins + df.Losses)
df['MVP Rank'] = numpy.where(df.Season <= 2023, df.groupby('Season')['Pts Won'].rank(ascending = False, method = 'dense'), 0.0)
df['Won MVP'] = numpy.where(df['MVP Rank'] == 1, 1, 0)
df.tail()

df_past = df[df.Season <= 2023]
df_current = df[df.Season == 2024]

df_past = df_past[df_past['Pts Won'] > 0]

corr = df_past.corr(method = 'pearson', numeric_only = True)
won_mvp_corr = corr[['Won MVP']]
won_mvp_corr['Won MVP'].abs().sort_values()

def plot_two_variables(df, title, var1, var1_order, var2, var2_order):
    matplotlib.pyplot.style.use('fivethirtyeight')
    fig, ax = matplotlib.pyplot.subplots()

    mvp = df[df['Won MVP'] == 1]
    not_mvp = df[df['Won MVP'] != 1]

    ax.scatter(mvp[var1], mvp[var2], label = 'MVP', marker = '^', s = 100)
    ax.scatter(not_mvp[var1], not_mvp[var2], label = 'Not MVP', alpha = 0.2)
    ax.legend(loc = 'best', prop = {'size': 12})
    ax.set_xlim(ax.get_xlim()[::var1_order])
    ax.set_ylim(ax.get_ylim()[::var2_order])
    ax.set_xlabel(var1, fontsize = 16)
    ax.set_ylabel(var2, fontsize = 16)

    fig.suptitle(title, weight = 'bold', size = 20)
    fig.text(x = -0.02, y = -0.08, s = '____________________________________________________', fontsize = 16, color = 'grey', horizontalalignment = 'left', alpha = 0.2)
    fig.text(x = -0.02, y = -0.16, s = 'https://crisbraatz.github.io', fontsize = 16, color = 'grey', horizontalalignment = 'left')

plot_two_variables(df_past, 'Player Win Share VS Team Overall Seed', 'Rk', -1, 'WS', 1)

df_past[(df_past['Won MVP'] == 1) & (df_past['Rk'] > 5)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%']]

plot_two_variables(df_past, 'Efficiency Rating VS Points Per Game', 'PTS', 1, 'PER', 1)

df_past[(df_past['Won MVP'] == 1) & (df_past['PTS'] <= 20)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%']]

plot_two_variables(df_past, 'Player Value of Replacement VS Team Overall Seed', 'Rk', -1, 'VORP', 1)

def build_features(df_train, df_test):
    mms = MinMaxScaler()

    x_train_mms = mms.fit_transform(df_train[['Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%',
                                              '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB',
                                              'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PER', 'TS%', '3PAr', 'FTr',
                                              'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS',
                                              'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Rk', 'Wins', 'Losses', 'W/L%', 'GS%', 'GP%']])
    x_test_mms = mms.transform(df_test[['Age', 'G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%',
                                        '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB',
                                        'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PER', 'TS%', '3PAr', 'FTr',
                                        'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS', 'DWS',
                                        'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'Rk', 'Wins', 'Losses', 'W/L%', 'GS%', 'GP%']])

    x_train = numpy.hstack([x_train_mms])
    x_test = numpy.hstack([x_test_mms])
    y_train = df_train['Won MVP'].values.reshape(-1, 1)
    y_test = df_test['Won MVP'].values.reshape(-1, 1)

    return x_train, y_train, x_test, y_test

model = LogisticRegression(solver = 'liblinear')

df_past_predicted = []
results_matrix = numpy.zeros(shape = (1, 2023 - 1980, 4, 2))
for season in range(1980, 2024):
    fold = season - 1980 - 1
    df_train = df_past[df_past.Season != season]
    df_test = df_past[df_past.Season == season]
    x_train, y_train, x_test, y_test = build_features(df_train, df_test)
    model.fit(x_train, y_train)

    df_train_rank = df_train.copy()
    df_train_rank['MVP Odds'] = model.predict_proba(x_train)[:, 1]
    df_train_rank['Predicted MVP Rank'] = df_train_rank.groupby('Season')['MVP Odds'].rank(ascending = False, method = 'dense')
    df_train_rank['Predicted MVP Winner'] = df_train_rank['Predicted MVP Rank']
    df_train_rank['Predicted MVP Winner'].loc[df_train_rank['Predicted MVP Winner'] != 1] = 0

    df_train_rank_won_mvp = df_train_rank['Won MVP']
    df_train_rank_predicted_mvp_winner = df_train_rank['Predicted MVP Winner']

    results_matrix[0, fold, 0, 0] = metrics.accuracy_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)
    results_matrix[0, fold, 1, 0] = metrics.precision_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)
    results_matrix[0, fold, 2, 0] = metrics.recall_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)
    results_matrix[0, fold, 3, 0] = metrics.f1_score(df_train_rank_won_mvp, df_train_rank_predicted_mvp_winner)

    df_test_rank = df_test.copy()
    df_test_rank['MVP Odds'] = model.predict_proba(x_test)[:, 1]

    df_past_predicted.append(df_test_rank)

    df_test_rank['Predicted MVP Rank'] = df_test_rank.groupby('Season')['MVP Odds'].rank(ascending = False, method = 'dense')
    df_test_rank['Predicted MVP Winner'] = df_test_rank['Predicted MVP Rank']
    df_test_rank['Predicted MVP Winner'].loc[df_test_rank['Predicted MVP Winner'] != 1] = 0

    df_test_rank_won_mvp = df_test_rank['Won MVP']
    df_test_rank_predicted_mvp_winner = df_test_rank['Predicted MVP Winner']

    results_matrix[0, fold, 0, 1] = metrics.accuracy_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)
    results_matrix[0, fold, 1, 1] = metrics.precision_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)
    results_matrix[0, fold, 2, 1] = metrics.recall_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)
    results_matrix[0, fold, 3, 1] = metrics.f1_score(df_test_rank_won_mvp, df_test_rank_predicted_mvp_winner)

df_past_predicted = pandas.concat(df_past_predicted)

print('Train')
print('Accuracy:', results_matrix[0, :, 0, 0].mean())
print('Precision:', results_matrix[0, :, 1, 0].mean())
print('Coverage:', results_matrix[0, :, 2, 0].mean())
print('F Measure:', results_matrix[0, :, 3, 0].mean())
print('Test')
print('Accuracy:', results_matrix[0, :, 0, 1].mean())
print('Precision:', results_matrix[0, :, 1, 1].mean())
print('Coverage:', results_matrix[0, :, 2, 1].mean())
print('F Measure:', results_matrix[0, :, 3, 1].mean())

df_past_predicted[(df_past_predicted['Won MVP'] == 1) & (df_past_predicted['Predicted MVP Winner'] != 1)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%', 'Predicted MVP Rank']]

df_past_predicted[(df_past_predicted['Won MVP'] != 1) & (df_past_predicted['Predicted MVP Winner'] == 1)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%', 'MVP Rank']]

df_past_predicted[(df_past_predicted['Won MVP'] == 1) & (df_past_predicted['Predicted MVP Winner'] == 1)][['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%']]

matplotlib.pyplot.title('Confusion Matrix - MVP Prediction')
seaborn.heatmap(confusion_matrix(df_past_predicted['Won MVP'], df_past_predicted['Predicted MVP Winner']), annot = True, fmt = '0.2f', cmap = 'rocket_r')
matplotlib.pyplot.text(x = -0.02, y = 2.16, s = '__________________________________________', fontsize = 16, color = 'grey', horizontalalignment = 'left', alpha = 0.2)
matplotlib.pyplot.text(x = -0.02, y = 2.32, s = 'https://crisbraatz.github.io', fontsize = 16, color = 'grey', horizontalalignment = 'left')
matplotlib.pyplot.show()

df_current = df_current[(df_current['GS%'] > 0.9) & (df_current['GP%'] > 0.8)]

x_train, y_train, x_test, y_test = build_features(df_past, df_current)

model.fit(x_train, y_train)

df_current['MVP Odds'] = model.predict_proba(x_test)[:, 1]
df_current['Predicted MVP Rank'] = df_current.groupby('Season')['MVP Odds'].rank(ascending = False, method = 'dense')
df_current['Predicted MVP Winner'] = df_current['Predicted MVP Rank']
df_current['Predicted MVP Winner'].loc[df_current['Predicted MVP Winner'] != 1] = 0

df_current.sort_values(by = ['Predicted MVP Rank'], ascending = True)[['Player', 'Tm', 'MP', 'PTS', 'TRB', 'AST', 'STL', 'BLK', 'FG%', '3P%', 'FT%', 'WS', 'WS/48', 'Season', 'Rk', 'Overall', 'W/L%', 'MVP Odds']].head(10)